{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras model evaluation workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.split(os.path.split(os.getcwd())[0])[0])\n",
    "\n",
    "config_filepath = os.path.join(os.getcwd(),\"config/evaluate_config_generator.json\")\n",
    "notebook_filepath = os.path.join(os.getcwd(),\"evaluate.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "import json_tricks\n",
    "import datetime\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from mercury_ml.common import utils\n",
    "from mercury_ml.common import tasks\n",
    "import mercury_ml.common\n",
    "import mercury_ml.tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "These functions will help with the flow of this particular notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_bunch(data_bunch):\n",
    "\n",
    "    for data_set_name, data_set in data_bunch.__dict__.items():\n",
    "        print(\"{} <{}>\".format(data_set_name, type(data_set).__name__))\n",
    "        for data_wrapper_name, data_wrapper in data_set.__dict__.items():\n",
    "            print(\"  {} <{}>\".format(data_wrapper_name, type(data_wrapper).__name__))\n",
    "        print()\n",
    "        \n",
    "def maybe_transform(data_bunch, pre_execution_parameters):\n",
    "    if pre_execution_parameters:\n",
    "        return data_bunch.transform(**pre_execution_parameters)\n",
    "    else:\n",
    "        return data_bunch\n",
    "        \n",
    "def print_dict(d):\n",
    "    print(json_tricks.dumps(d, indent=2))\n",
    "\n",
    "def get_installed_packages():\n",
    "    import pip\n",
    "    try:\n",
    "        from pip._internal.operations import freeze\n",
    "    except ImportError:  # pip < 10.0\n",
    "        from pip.operations import freeze\n",
    "\n",
    "    packages = []\n",
    "    for p in freeze.freeze():\n",
    "        packages.append(p)\n",
    "\n",
    "    return packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_referenced_json_config(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"global_references\": {\n",
      "    \"number_of_classes\": 2,\n",
      "    \"batch_size\": 2,\n",
      "    \"labels\": [\n",
      "      \"cat\",\n",
      "      \"dog\"\n",
      "    ]\n",
      "  },\n",
      "  \"meta_info\": {\n",
      "    \"ml_engine\": \"keras (tensorflow)\",\n",
      "    \"model_purpose\": \"test_generator\",\n",
      "    \"session_id\": \"51cac0a6\",\n",
      "    \"model_object_name\": \"{model_purpose}__{session_id}\",\n",
      "    \"data_bunch_name\": \"images_456\",\n",
      "    \"evaluation_session_id\": \"{evaluation_session_id}\",\n",
      "    \"notebook_filepath\": \"{notebook_filepath}\",\n",
      "    \"config_filepath\": \"{config_filepath}\"\n",
      "  },\n",
      "  \"init\": {\n",
      "    \"read_source_data\": {\n",
      "      \"name\": \"read_disk_keras_single_input_iterator\"\n",
      "    },\n",
      "    \"get_loss_function\": {\n",
      "      \"name\": \"get_custom_loss\"\n",
      "    },\n",
      "    \"load_model\": {\n",
      "      \"name\": \"load_hdf5\"\n",
      "    },\n",
      "    \"copy_from_local_to_remote\": {\n",
      "      \"name\": \"copy_from_disk_to_disk\",\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"copy_from_remote_to_local\": {\n",
      "      \"name\": \"copy_from_disk_to_disk\",\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"evaluate\": {\n",
      "      \"name\": \"evaluate_generator\"\n",
      "    },\n",
      "    \"predict\": {\n",
      "      \"name\": \"predict_generator\"\n",
      "    },\n",
      "    \"custom_metrics\": {\n",
      "      \"names\": [\n",
      "        \"evaluate_numpy_auc\",\n",
      "        \"evaluate_numpy_micro_auc\"\n",
      "      ]\n",
      "    },\n",
      "    \"custom_label_metrics\": {\n",
      "      \"names\": [\n",
      "        \"evaluate_numpy_accuracy\",\n",
      "        \"evaluate_numpy_confusion_matrix\"\n",
      "      ]\n",
      "    },\n",
      "    \"store_prediction_artifact_locally\": {\n",
      "      \"name\": \"store_pandas_pickle\"\n",
      "    },\n",
      "    \"store_artifact_locally\": {\n",
      "      \"name\": \"store_dict_json\"\n",
      "    }\n",
      "  },\n",
      "  \"exec\": {\n",
      "    \"read_source_data\": {\n",
      "      \"params\": {\n",
      "        \"test_params\": {\n",
      "          \"generator_params\": {},\n",
      "          \"iterator_params\": {\n",
      "            \"directory\": \"./example_data/{data_bunch_name}/test\",\n",
      "            \"batch_size\": 2,\n",
      "            \"class_mode\": \"categorical\",\n",
      "            \"color_mode\": \"rgb\",\n",
      "            \"seed\": 12345,\n",
      "            \"shuffle\": false,\n",
      "            \"target_size\": [\n",
      "              10,\n",
      "              10\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"get_loss_function\": {\n",
      "      \"params\": {\n",
      "        \"loss_function_getter_name\": \"get_mock_loss_function\",\n",
      "        \"loss_function_getter_params\": {\n",
      "          \"mock_value\": 42\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"evaluate\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"predict\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"load_model\": {\n",
      "      \"local_dir\": \"./example_results/local/{session_id}/models\",\n",
      "      \"remote_dir\": \"./example_results/remote/{session_id}/models\",\n",
      "      \"filename\": \"{model_object_name}__hdf5\",\n",
      "      \"extension\": \".h5\",\n",
      "      \"always_fetch_remote\": false\n",
      "    },\n",
      "    \"evaluate_custom_metrics\": {\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"numpy\",\n",
      "          \"data_wrapper_params\": {\n",
      "            \"predictions\": {},\n",
      "            \"index\": {},\n",
      "            \"targets\": {}\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"evaluate_custom_label_metrics\": {\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {}\n",
      "    },\n",
      "    \"save_evaluation_session\": {\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/{session_id}/evaluation_session/{evaluation_session_id}\",\n",
      "        \"remote_dir\": \"./example_results/remote/{session_id}/evaluation_session/{evaluation_session_id}\",\n",
      "        \"filename\": \"evaluation_session\"\n",
      "      }\n",
      "    },\n",
      "    \"save_evaluation_session_artifacts\": {\n",
      "      \"artifacts\": [\n",
      "        {\n",
      "          \"artifact_path\": \"{config_filepath}\",\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/evaluation_session/{evaluation_session_id}\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/evaluation_session/{evaluation_session_id}\"\n",
      "        },\n",
      "        {\n",
      "          \"artifact_path\": \"{notebook_filepath}\",\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/evaluation_session/{evaluation_session_id}\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/evaluation_session/{evaluation_session_id}\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"save_formatted_config\": {\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/{session_id}/evaluation_session/{evaluation_session_id}\",\n",
      "        \"remote_dir\": \"./example_results/remote/{session_id}/evaluation_session/{evaluation_session_id}\",\n",
      "        \"filename\": \"config_formatted\"\n",
      "      }\n",
      "    },\n",
      "    \"prepare_predictions_for_storage\": {\n",
      "      \"pre_execution_transformation\": {\n",
      "        \"data_set_names\": [\n",
      "          \"test\"\n",
      "        ],\n",
      "        \"params\": {\n",
      "          \"transform_to\": \"pandas\",\n",
      "          \"data_wrapper_params\": {\n",
      "            \"predictions\": {},\n",
      "            \"index\": {},\n",
      "            \"targets\": {}\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"data_set_names\": [\n",
      "        \"test\"\n",
      "      ],\n",
      "      \"params\": {\n",
      "        \"predictions\": {\n",
      "          \"left_data_wrapper_name\": \"index\",\n",
      "          \"right_data_wrapper_name\": \"predictions\",\n",
      "          \"new_data_wrapper_name\": \"predictions_for_storage\"\n",
      "        },\n",
      "        \"targets\": {\n",
      "          \"left_data_wrapper_name\": \"index\",\n",
      "          \"right_data_wrapper_name\": \"targets\",\n",
      "          \"new_data_wrapper_name\": \"targets_for_storage\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_predictions\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"data_wrapper_name\": \"predictions_for_storage\",\n",
      "          \"params\": {\n",
      "            \"local_dir\": \"./example_results/local/{session_id}/predictions/test\",\n",
      "            \"remote_dir\": \"./example_results/remote/{session_id}/predictions/test\",\n",
      "            \"filename\": \"{model_object_name}__test__predictions\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_targets\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"data_wrapper_name\": \"targets_for_storage\",\n",
      "          \"params\": {\n",
      "            \"local_dir\": \"./example_results/local/{session_id}/predictions/test\",\n",
      "            \"remote_dir\": \"./example_results/remote/{session_id}/predictions/test\",\n",
      "            \"filename\": \"{model_object_name}__test__targets\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/metrics/test\",\n",
      "          \"filename\": \"{model_object_name}__test__keras_metrics\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_custom_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/metrics/test\",\n",
      "          \"filename\": \"{model_object_name}__test__custom_metrics\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"save_custom_label_metrics\": {\n",
      "      \"data_sets\": {\n",
      "        \"test\": {\n",
      "          \"local_dir\": \"./example_results/local/{session_id}/metrics/test\",\n",
      "          \"remote_dir\": \"./example_results/remote/{session_id}/metrics/test\",\n",
      "          \"filename\": \"{model_object_name}__test__custom_label_metrics\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_dict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_session_id = str(uuid.uuid4().hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca995584eca24b83b6bc1829f839a0ea\n"
     ]
    }
   ],
   "source": [
    "print(evaluation_session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update config\n",
    "\n",
    "The function `utils.recursively_update_config(config, string_formatting_dict)` allows us to use string formatting to replace placeholder strings with acctual values.\n",
    "\n",
    "for example: \n",
    "\n",
    "```python\n",
    ">>> config = {\"some_value\": \"some_string_{some_placeholder}\"}\n",
    ">>> string_formatting_dict = {\"some_placeholder\": \"ABC\"}\n",
    ">>> utils.recursively_update_config(config, string_formatting_dict)\n",
    ">>> print(config)\n",
    "{\"some_value\": \"some_string_ABC}\"}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First update `config[\"meta_info\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.recursively_update_config(config[\"meta_info\"], {\n",
    "    \"evaluation_session_id\": evaluation_session_id,\n",
    "    \"session_id\": config[\"meta_info\"][\"session_id\"],\n",
    "    \"model_purpose\": config[\"meta_info\"][\"model_purpose\"],\n",
    "    \"config_filepath\": config_filepath,\n",
    "    \"notebook_filepath\": notebook_filepath\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use `config[\"meta_info\"]` to update the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.recursively_update_config(config, config[\"meta_info\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "\n",
    "Create a small dictionary with the session information. This will later be stored as a dictionary artifact with all the key run infomration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_session = {\n",
    "    \"time_stamp\": datetime.datetime.utcnow().isoformat()[:-3] + \"Z\",\n",
    "    \"run_by\": getpass.getuser(),\n",
    "    \"meta_info\": config[\"meta_info\"],\n",
    "    \"installed_packages\": get_installed_packages()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session info\n",
      "{\n",
      "  \"time_stamp\": \"2019-05-08T14:22:50.989Z\",\n",
      "  \"run_by\": \"karl.schriek\",\n",
      "  \"meta_info\": {\n",
      "    \"ml_engine\": \"keras (tensorflow)\",\n",
      "    \"model_purpose\": \"test_generator\",\n",
      "    \"session_id\": \"51cac0a6\",\n",
      "    \"model_object_name\": \"test_generator__51cac0a6\",\n",
      "    \"data_bunch_name\": \"images_456\",\n",
      "    \"evaluation_session_id\": \"ca995584eca24b83b6bc1829f839a0ea\",\n",
      "    \"notebook_filepath\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml\\\\examples\\\\tensorflow\\\\evaluate.ipynb\",\n",
      "    \"config_filepath\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml\\\\examples\\\\tensorflow\\\\config/evaluate_config_generator.json\"\n",
      "  },\n",
      "  \"installed_packages\": [\n",
      "    \"absl-py==0.7.1\",\n",
      "    \"astor==0.7.1\",\n",
      "    \"atomicwrites==1.3.0\",\n",
      "    \"attrs==19.1.0\",\n",
      "    \"backcall==0.1.0\",\n",
      "    \"bleach==3.1.0\",\n",
      "    \"boto3==1.9.115\",\n",
      "    \"botocore==1.12.115\",\n",
      "    \"certifi==2019.3.9\",\n",
      "    \"chardet==3.0.4\",\n",
      "    \"colorama==0.4.1\",\n",
      "    \"cycler==0.10.0\",\n",
      "    \"decorator==4.3.2\",\n",
      "    \"defusedxml==0.5.0\",\n",
      "    \"docutils==0.14\",\n",
      "    \"entrypoints==0.3\",\n",
      "    \"future==0.17.1\",\n",
      "    \"gast==0.2.2\",\n",
      "    \"google-pasta==0.1.4\",\n",
      "    \"grpcio==1.19.0\",\n",
      "    \"h2o==3.24.0.1\",\n",
      "    \"h5py==2.9.0\",\n",
      "    \"idna==2.8\",\n",
      "    \"ipykernel==5.1.0\",\n",
      "    \"ipython==7.3.0\",\n",
      "    \"ipython-genutils==0.2.0\",\n",
      "    \"ipywidgets==7.4.2\",\n",
      "    \"jedi==0.13.3\",\n",
      "    \"Jinja2==2.10\",\n",
      "    \"jmespath==0.9.4\",\n",
      "    \"json-tricks==3.13.1\",\n",
      "    \"jsonref==0.2\",\n",
      "    \"jsonschema==3.0.1\",\n",
      "    \"jupyter==1.0.0\",\n",
      "    \"jupyter-client==5.2.4\",\n",
      "    \"jupyter-console==6.0.0\",\n",
      "    \"jupyter-core==4.4.0\",\n",
      "    \"jupytext==1.0.3\",\n",
      "    \"Keras-Applications==1.0.7\",\n",
      "    \"Keras-Preprocessing==1.0.9\",\n",
      "    \"kiwisolver==1.1.0\",\n",
      "    \"Markdown==3.0.1\",\n",
      "    \"MarkupSafe==1.1.1\",\n",
      "    \"matplotlib==3.0.3\",\n",
      "    \"mercury-ml==0.2.2\",\n",
      "    \"mistune==0.8.4\",\n",
      "    \"mock==2.0.0\",\n",
      "    \"more-itertools==7.0.0\",\n",
      "    \"nbconvert==5.4.1\",\n",
      "    \"nbformat==4.4.0\",\n",
      "    \"notebook==5.7.6\",\n",
      "    \"numpy==1.16.2\",\n",
      "    \"opencv-python==4.1.0.25\",\n",
      "    \"pandas==0.24.2\",\n",
      "    \"pandocfilters==1.4.2\",\n",
      "    \"parso==0.3.4\",\n",
      "    \"pbr==5.1.3\",\n",
      "    \"pickleshare==0.7.5\",\n",
      "    \"Pillow==5.4.1\",\n",
      "    \"pip==19.0.3\",\n",
      "    \"pkginfo==1.5.0.1\",\n",
      "    \"pluggy==0.9.0\",\n",
      "    \"prometheus-client==0.6.0\",\n",
      "    \"prompt-toolkit==2.0.9\",\n",
      "    \"protobuf==3.7.0\",\n",
      "    \"py==1.8.0\",\n",
      "    \"py4j==0.10.7\",\n",
      "    \"Pygments==2.3.1\",\n",
      "    \"pymongo==3.7.2\",\n",
      "    \"pyparsing==2.4.0\",\n",
      "    \"pyrsistent==0.14.11\",\n",
      "    \"pyspark==2.4.0\",\n",
      "    \"pytest==4.4.0\",\n",
      "    \"python-dateutil==2.8.0\",\n",
      "    \"pytz==2018.9\",\n",
      "    \"pywinpty==0.5.5\",\n",
      "    \"PyYAML==5.1\",\n",
      "    \"pyzmq==18.0.1\",\n",
      "    \"qtconsole==4.4.3\",\n",
      "    \"readme-renderer==24.0\",\n",
      "    \"requests==2.21.0\",\n",
      "    \"requests-toolbelt==0.9.1\",\n",
      "    \"s3transfer==0.2.0\",\n",
      "    \"scikit-learn==0.20.3\",\n",
      "    \"scipy==1.2.1\",\n",
      "    \"Send2Trash==1.5.0\",\n",
      "    \"setuptools==40.8.0\",\n",
      "    \"six==1.12.0\",\n",
      "    \"sklearn==0.0\",\n",
      "    \"tabulate==0.8.3\",\n",
      "    \"tb-nightly==1.14.0a20190301\",\n",
      "    \"tensorboard==1.13.1\",\n",
      "    \"tensorflow==2.0.0a0\",\n",
      "    \"tensorflow-estimator==1.13.0\",\n",
      "    \"tensorflow-serving-api==1.13.0\",\n",
      "    \"termcolor==1.1.0\",\n",
      "    \"terminado==0.8.1\",\n",
      "    \"testfixtures==6.6.1\",\n",
      "    \"testpath==0.4.2\",\n",
      "    \"tf-estimator-nightly==1.14.0.dev2019030115\",\n",
      "    \"tornado==6.0.1\",\n",
      "    \"tqdm==4.31.1\",\n",
      "    \"traitlets==4.3.2\",\n",
      "    \"twine==1.13.0\",\n",
      "    \"urllib3==1.24.1\",\n",
      "    \"wcwidth==0.1.7\",\n",
      "    \"webencodings==0.5.1\",\n",
      "    \"Werkzeug==0.14.1\",\n",
      "    \"wheel==0.33.1\",\n",
      "    \"widgetsnbextension==3.4.2\",\n",
      "    \"wincertstore==0.2\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Session info\")\n",
    "print(json.dumps(evaluation_session, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "These are the functions or classes we will be using in this workflow. We get / instatiate them all at the beginning using parameters under `config[\"initialization\"]`.\n",
    "\n",
    "Here we use mainly use `getattr` to fetch them via the alias containers based on a string input in the config file. Providers could however also be fetched directly. The following three methods are all equivalent:\n",
    "\n",
    "```python\n",
    "# 1. (what we are using in this notebook)\n",
    "import mercury_ml.common\n",
    "source_reader=getattr(mercury_ml.common.SourceReaders, \"read_pandas_data_set\")\n",
    "\n",
    "# 2. \n",
    "import mercury_ml.common\n",
    "source_reader=mercury_ml.common.SourceReaders.read_pandas_data_set\n",
    "\n",
    "# 3.\n",
    "from mercury_ml.common.source_reading import read_pandas_data_set\n",
    "source_reader=read_pandas_data_set\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "\n",
    "These helper functions will create instantiate class providers (`create_and_log`) or fetch function providers (`get_and_log`) based on the parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_log(container, class_name, params):\n",
    "    provider = getattr(container, class_name)(**params)\n",
    "    print(\"{}.{}\".format(container.__name__, class_name))\n",
    "    print(\"params: \", json.dumps(params, indent=2))\n",
    "    return provider\n",
    "\n",
    "def get_and_log(container, function_name):\n",
    "    provider = getattr(container, function_name)\n",
    "    print(\"{}.{}\".format(container.__name__, function_name))\n",
    "    return provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common\n",
    "\n",
    "These are providers that are universally relevant, regardless of which Machine Learning engine is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalArtifactStorers.store_dict_json\n"
     ]
    }
   ],
   "source": [
    "# a function for storing dictionary artifacts to local disk\n",
    "store_artifact_locally = get_and_log(mercury_ml.common.LocalArtifactStorers,\n",
    "                                     config[\"init\"][\"store_artifact_locally\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalArtifactStorers.store_pandas_pickle\n"
     ]
    }
   ],
   "source": [
    "# a function for storing data-frame-like artifacts to local disk\n",
    "store_prediction_artifact_locally = get_and_log(mercury_ml.common.LocalArtifactStorers,\n",
    "                                                config[\"init\"][\"store_prediction_artifact_locally\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArtifactCopiers.copy_from_disk_to_disk\n"
     ]
    }
   ],
   "source": [
    "# a function for copy artifacts from local disk to a remote store\n",
    "copy_from_local_to_remote = get_and_log(mercury_ml.common.ArtifactCopiers, config[\"init\"][\"copy_from_local_to_remote\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArtifactCopiers.copy_from_disk_to_disk\n"
     ]
    }
   ],
   "source": [
    "# a function for copy artifacts from remote store to a local disk\n",
    "copy_from_remote_to_local = get_and_log(mercury_ml.common.ArtifactCopiers, config[\"init\"][\"copy_from_remote_to_local\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SourceReaders.read_disk_keras_single_input_iterator\n"
     ]
    }
   ],
   "source": [
    "# a function for reading source data. When called it will return an instance of type DataBunch \n",
    "read_source_data_set = get_and_log(mercury_ml.common.SourceReaders, config[\"init\"][\"read_source_data\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomMetrics.evaluate_numpy_auc\n",
      "CustomMetrics.evaluate_numpy_micro_auc\n"
     ]
    }
   ],
   "source": [
    "# a dictionary of functions that calculate custom metrics\n",
    "custom_metrics_dict = {\n",
    "    custom_metric_name: get_and_log(mercury_ml.common.CustomMetrics, custom_metric_name) for custom_metric_name in config[\"init\"][\"custom_metrics\"][\"names\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomLabelMetrics.evaluate_numpy_accuracy\n",
      "CustomLabelMetrics.evaluate_numpy_confusion_matrix\n"
     ]
    }
   ],
   "source": [
    "# a dictionary of functions that calculate custom label metrics\n",
    "custom_label_metrics_dict = {\n",
    "    custom_label_metric_name: get_and_log(mercury_ml.common.CustomLabelMetrics, custom_label_metric_name) for custom_label_metric_name in config[\"init\"][\"custom_label_metrics\"][\"names\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LossFunctionFetchers.get_custom_loss\n"
     ]
    }
   ],
   "source": [
    "# a function that returns a keras loss function\n",
    "get_loss_function = get_and_log(mercury_ml.tensorflow.LossFunctionFetchers, \n",
    "                                config[\"init\"][\"get_loss_function\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelLoaders.load_hdf5\n"
     ]
    }
   ],
   "source": [
    "# a function that loads a Keras model\n",
    "load_model = get_and_log(mercury_ml.tensorflow.ModelLoaders, config[\"init\"][\"load_model\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelEvaluators.evaluate_generator\n"
     ]
    }
   ],
   "source": [
    "# a function for evaluating keras metrics\n",
    "evaluate = get_and_log(mercury_ml.tensorflow.ModelEvaluators, config[\"init\"][\"evaluate\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionFunctions.predict_generator\n"
     ]
    }
   ],
   "source": [
    "# a function that predictions using a keras model\n",
    "predict = get_and_log(mercury_ml.tensorflow.PredictionFunctions, config[\"init\"][\"predict\"][\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "Here we use the providers defined above to execute various tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 2 classes.\n",
      "Source data read using following parameters: \n",
      "\n",
      "{\n",
      "  \"test_params\": {\n",
      "    \"generator_params\": {},\n",
      "    \"iterator_params\": {\n",
      "      \"directory\": \"./example_data/images_456/test\",\n",
      "      \"batch_size\": 2,\n",
      "      \"class_mode\": \"categorical\",\n",
      "      \"color_mode\": \"rgb\",\n",
      "      \"seed\": 12345,\n",
      "      \"shuffle\": false,\n",
      "      \"target_size\": [\n",
      "        10,\n",
      "        10\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_bunch_source = tasks.read_test_data_bunch(read_source_data_set,**config[\"exec\"][\"read_source_data\"][\"params\"] )\n",
    "print(\"Source data read using following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"read_source_data\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  features <KerasIteratorFeaturesDataWrapper>\n",
      "  targets <KerasIteratorTargetsDataWrapper>\n",
      "  index <KerasIteratorIndexDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Read data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"init\"][\"get_loss_function\"][\"name\"] == \"get_custom_loss\":\n",
    "    loss = get_loss_function(**config[\"exec\"][\"get_loss_function\"][\"params\"])\n",
    "    custom_objects = {loss.__name__: loss}\n",
    "else:\n",
    "    custom_objects = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mock_loss': <function get_mock_loss_function.<locals>.mock_loss at 0x0000019E0A8B2950>}\n"
     ]
    }
   ],
   "source": [
    "print(custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.load_model(load_model=load_model,\n",
    "                         copy_from_remote_to_local=copy_from_remote_to_local,\n",
    "                         custom_objects = custom_objects,\n",
    "                         **config[\"exec\"][\"load_model\"]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save (formatted) config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, config,\n",
    "                      **config[\"exec\"][\"save_formatted_config\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config stored with following parameters\n",
      "{\n",
      "  \"local_dir\": \"./example_results/local/51cac0a6/evaluation_session/ca995584eca24b83b6bc1829f839a0ea\",\n",
      "  \"remote_dir\": \"./example_results/remote/51cac0a6/evaluation_session/ca995584eca24b83b6bc1829f839a0ea\",\n",
      "  \"filename\": \"config_formatted\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Config stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_formatted_config\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save session info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, evaluation_session,\n",
    "                      **config[\"exec\"][\"save_evaluation_session\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session dictionary stored with following parameters\n",
      "{\n",
      "  \"local_dir\": \"./example_results/local/51cac0a6/evaluation_session/ca995584eca24b83b6bc1829f839a0ea\",\n",
      "  \"remote_dir\": \"./example_results/remote/51cac0a6/evaluation_session/ca995584eca24b83b6bc1829f839a0ea\",\n",
      "  \"filename\": \"evaluation_session\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Session dictionary stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_evaluation_session\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save session artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for artifact_dict in config[\"exec\"][\"save_evaluation_session_artifacts\"][\"artifacts\"]:\n",
    "    \n",
    "    artifact_dir=os.path.dirname(artifact_dict[\"artifact_path\"]) \n",
    "    artifact_filename=os.path.basename(artifact_dict[\"artifact_path\"])\n",
    "    \n",
    "    # save to local artifact store\n",
    "    mercury_ml.common.ArtifactCopiers.copy_from_disk_to_disk(\n",
    "        source_dir=artifact_dir,\n",
    "        target_dir=artifact_dict[\"local_dir\"],\n",
    "        filename=artifact_filename,\n",
    "        overwrite=False,\n",
    "        delete_source=False)\n",
    "\n",
    "    # copy to remote artifact store\n",
    "    copy_from_local_to_remote(source_dir=artifact_dict[\"local_dir\"],\n",
    "                              target_dir=artifact_dict[\"remote_dir\"],\n",
    "                              filename=artifact_filename,\n",
    "                              overwrite=False,\n",
    "                              delete_source=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session artifacts stored with following parameters\n",
      "{\n",
      "  \"artifacts\": [\n",
      "    {\n",
      "      \"artifact_path\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml\\\\examples\\\\tensorflow\\\\config/evaluate_config_generator.json\",\n",
      "      \"local_dir\": \"./example_results/local/51cac0a6/evaluation_session/ca995584eca24b83b6bc1829f839a0ea\",\n",
      "      \"remote_dir\": \"./example_results/remote/51cac0a6/evaluation_session/ca995584eca24b83b6bc1829f839a0ea\"\n",
      "    },\n",
      "    {\n",
      "      \"artifact_path\": \"C:\\\\Users\\\\karl.schriek\\\\PycharmProjects\\\\mercury-ml\\\\examples\\\\tensorflow\\\\evaluate.ipynb\",\n",
      "      \"local_dir\": \"./example_results/local/51cac0a6/evaluation_session/ca995584eca24b83b6bc1829f839a0ea\",\n",
      "      \"remote_dir\": \"./example_results/remote/51cac0a6/evaluation_session/ca995584eca24b83b6bc1829f839a0ea\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Session artifacts stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_evaluation_session_artifacts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed with following parameters: \n",
      "\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "data_bunch_metrics = maybe_transform(data_bunch_source, config[\"exec\"][\"evaluate\"].get(\"pre_execution_transformation\"))\n",
    "\n",
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"evaluate\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  features <KerasIteratorFeaturesDataWrapper>\n",
      "  targets <KerasIteratorTargetsDataWrapper>\n",
      "  index <KerasIteratorIndexDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_metrics, data_set_name)\n",
    "    metrics[data_set_name] = evaluate(model, data_set, **config[\"exec\"][\"evaluate\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0508 16:22:52.890580 17608 encoders.py:368] json-tricks: numpy scalar serialization is experimental and may work differently in future versions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting metrics: \n",
      "\n",
      "{\n",
      "  \"test\": {\n",
      "    \"loss\": 0.6931471625963846,\n",
      "    \"acc\": 0.5\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Resulting metrics: \\n\")\n",
    "print_dict(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO existing metrics should be updated, not overwritten!\n",
    "\n",
    "for data_set_name, params in config[\"exec\"][\"save_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, metrics[data_set_name],\n",
    "                          **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed with following parameters: \n",
      "\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "data_bunch_predict = maybe_transform(data_bunch_metrics, config[\"exec\"][\"predict\"].get(\"pre_execution_transformation\"))\n",
    "\n",
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"predict\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  features <KerasIteratorFeaturesDataWrapper>\n",
      "  targets <KerasIteratorTargetsDataWrapper>\n",
      "  index <KerasIteratorIndexDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name in config[\"exec\"][\"predict\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_predict, data_set_name)\n",
    "    data_set.predictions = predict(model=model, data_set=data_set, **config[\"exec\"][\"predict\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data predicted with following parameters: \n",
      "\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(\"Data predicted with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"predict\"].get(\"params\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_custom_metrics = maybe_transform(data_bunch_predict, \n",
    "                                            config[\"exec\"][\"evaluate_custom_metrics\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_set_names\": [\n",
      "    \"test\"\n",
      "  ],\n",
      "  \"params\": {\n",
      "    \"transform_to\": \"numpy\",\n",
      "    \"data_wrapper_params\": {\n",
      "      \"predictions\": {},\n",
      "      \"index\": {},\n",
      "      \"targets\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"evaluate_custom_metrics\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  predictions <NumpyDataWrapper>\n",
      "  index <NumpyDataWrapper>\n",
      "  targets <NumpyDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_custom_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate custom metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "custom_metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate_custom_metrics\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_custom_metrics, data_set_name)\n",
    "    custom_metrics[data_set_name]  = tasks.evaluate_metrics(data_set, custom_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting custom metrics: \n",
      "\n",
      "{\n",
      "  \"test\": {\n",
      "    \"evaluate_numpy_auc\": 0.5,\n",
      "    \"evaluate_numpy_micro_auc\": 0.5\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Resulting custom metrics: \\n\")\n",
    "print_dict(custom_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate custom label metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_label_metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate_custom_label_metrics\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_custom_metrics, data_set_name)\n",
    "    custom_label_metrics[data_set_name] = tasks.evaluate_label_metrics(data_set, custom_label_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting custom label metrics: \n",
      "\n",
      "{\n",
      "  \"test\": {\n",
      "    \"Accuracy\": {\n",
      "      \"cat\": 0.5,\n",
      "      \"dog\": 0.5\n",
      "    },\n",
      "    \"ConfMat_Count_cat\": {\n",
      "      \"cat\": 3,\n",
      "      \"dog\": 3\n",
      "    },\n",
      "    \"ConfMat_Rate_cat\": {\n",
      "      \"cat\": 1.0,\n",
      "      \"dog\": 1.0\n",
      "    },\n",
      "    \"ConfMat_Count_dog\": {\n",
      "      \"cat\": 0,\n",
      "      \"dog\": 0\n",
      "    },\n",
      "    \"ConfMat_Rate_dog\": {\n",
      "      \"cat\": 0.0,\n",
      "      \"dog\": 0.0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Resulting custom label metrics: \\n\")\n",
    "print_dict(custom_label_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_custom_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote,\n",
    "                          custom_metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom metrics saved with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_sets\": {\n",
      "    \"test\": {\n",
      "      \"local_dir\": \"./example_results/local/51cac0a6/metrics/test\",\n",
      "      \"remote_dir\": \"./example_results/remote/51cac0a6/metrics/test\",\n",
      "      \"filename\": \"test_generator__51cac0a6__test__custom_metrics\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom metrics saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_custom_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_custom_label_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote,\n",
    "                          custom_label_metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom label metrics saved with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_sets\": {\n",
      "    \"test\": {\n",
      "      \"local_dir\": \"./example_results/local/51cac0a6/metrics/test\",\n",
      "      \"remote_dir\": \"./example_results/remote/51cac0a6/metrics/test\",\n",
      "      \"filename\": \"test_generator__51cac0a6__test__custom_label_metrics\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Custom label metrics saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_custom_label_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare predictions for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_prediction_preparation = maybe_transform(data_bunch_predict, \n",
    "                                                    config[\"exec\"][\"prepare_predictions_for_storage\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  predictions <PandasDataWrapper>\n",
      "  index <PandasDataWrapper>\n",
      "  targets <PandasDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_prediction_preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare predictions and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name in config[\"exec\"][\"prepare_predictions_for_storage\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_prediction_preparation, data_set_name)\n",
    "    data_set.add_data_wrapper_via_concatenate(**config[\"exec\"][\"prepare_predictions_for_storage\"][\"params\"][\"predictions\"])\n",
    "    data_set.add_data_wrapper_via_concatenate(**config[\"exec\"][\"prepare_predictions_for_storage\"][\"params\"][\"targets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_prediction_storage = maybe_transform(data_bunch_prediction_preparation, \n",
    "                                                config[\"exec\"][\"save_predictions\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data_bunch consists of: \n",
      "\n",
      "test <DataSet>\n",
      "  predictions <PandasDataWrapper>\n",
      "  index <PandasDataWrapper>\n",
      "  targets <PandasDataWrapper>\n",
      "  predictions_for_storage <PandasDataWrapper>\n",
      "  targets_for_storage <PandasDataWrapper>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_prediction_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, data_set_params in config[\"exec\"][\"save_predictions\"][\"data_sets\"].items():\n",
    "    data_set = getattr(data_bunch_prediction_storage, data_set_name)\n",
    "    data_wrapper = getattr(data_set, data_set_params[\"data_wrapper_name\"])\n",
    "    \n",
    "    data_to_store = data_wrapper.underlying\n",
    "   \n",
    "    tasks.store_artifacts(store_prediction_artifact_locally, copy_from_local_to_remote,\n",
    "                          data_to_store, **data_set_params[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_sets\": {\n",
      "    \"test\": {\n",
      "      \"data_wrapper_name\": \"predictions_for_storage\",\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/51cac0a6/predictions/test\",\n",
      "        \"remote_dir\": \"./example_results/remote/51cac0a6/predictions/test\",\n",
      "        \"filename\": \"test_generator__51cac0a6__test__predictions\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, data_set_params in config[\"exec\"][\"save_targets\"][\"data_sets\"].items():\n",
    "    data_set = getattr(data_bunch_prediction_storage, data_set_name)\n",
    "    data_wrapper = getattr(data_set, data_set_params[\"data_wrapper_name\"])\n",
    "    \n",
    "    data_to_store = data_wrapper.underlying\n",
    "   \n",
    "    tasks.store_artifacts(store_prediction_artifact_locally, copy_from_local_to_remote,\n",
    "                          data_to_store, **data_set_params[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets saved with following parameters: \n",
      "\n",
      "{\n",
      "  \"data_sets\": {\n",
      "    \"test\": {\n",
      "      \"data_wrapper_name\": \"targets_for_storage\",\n",
      "      \"params\": {\n",
      "        \"local_dir\": \"./example_results/local/51cac0a6/predictions/test\",\n",
      "        \"remote_dir\": \"./example_results/remote/51cac0a6/predictions/test\",\n",
      "        \"filename\": \"test_generator__51cac0a6__test__targets\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Targets saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_targets\"])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
