{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Workflow - minimal example\n",
    "\n",
    "The following is intended as an example that simplifies the number of steps, and uses the Mercury-ML function directly, rather than referencing and resolving function via a config file. It is not meant as a recommended \"best practice\" (for that, please see fit.ipynb), but instead is meant as a way to understand what is happening under the hood. Before going through this example, consider also first reviewing the small example scripts found under /examples/snippets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.split(os.path.split(os.getcwd())[0])[0])\n",
    "import uuid\n",
    "import json\n",
    "import json_tricks\n",
    "import copy\n",
    "\n",
    "from mercury_ml.common import tasks, utils, SourceReaders, ArtifactCopiers, CustomMetrics, CustomLabelMetrics\n",
    "from mercury_ml.tensorflow import ModelDefinitions, CallBacks, ModelCompilers, OptimizerFetchers, ModelFitters, \\\n",
    "LossFunctionFetchers, ModelSavers, ModelEvaluators, PredictionFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "\n",
    "We assign a unique session ID that will be used throughout to store artifacts produced during the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4().hex[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966e93da\n"
     ]
    }
   ],
   "source": [
    "print(session_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Source\n",
    "Here we set the parameters needed to reading the source data, and then proceed to use the task \"read_train_valid_test_data_bunch\" from the mercury_ml.common.tasks API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "input_data_folder= \"images_456\"\n",
    "\n",
    "source_params ={\n",
    "    \"train\":{\n",
    "          \"generator_params\": {\n",
    "            \"data_format\": \"channels_last\",\n",
    "            \"rescale\": 1./255,\n",
    "          },\n",
    "          \"iterator_params\": {\n",
    "            \"directory\": \"./example_data/{}/train\".format(input_data_folder),\n",
    "            \"batch_size\": 2,\n",
    "            \"class_mode\": \"categorical\",\n",
    "            \"color_mode\": \"rgb\",\n",
    "            \"shuffle\": True,\n",
    "            \"target_size\": [10, 10]\n",
    "          }\n",
    "        },\n",
    "    \"valid\": {\n",
    "          \"generator_params\": {\n",
    "            \"data_format\": \"channels_last\",\n",
    "            \"rescale\": 1./255,\n",
    "          },\n",
    "          \"iterator_params\": {\n",
    "            \"directory\": \"./example_data/{}/valid\".format(input_data_folder),\n",
    "            \"batch_size\": 2,\n",
    "            \"class_mode\": \"categorical\",\n",
    "            \"color_mode\": \"rgb\",\n",
    "            \"shuffle\": False,\n",
    "            \"target_size\": [10, 10]\n",
    "          }\n",
    "        },\n",
    "    \"test\":{\n",
    "          \"generator_params\": {\n",
    "            \"data_format\": \"channels_last\",\n",
    "            \"rescale\": 1./255,\n",
    "          },\n",
    "          \"iterator_params\": {\n",
    "            \"directory\": \"./example_data/{}/test\".format(input_data_folder),\n",
    "            \"batch_size\": 2,\n",
    "            \"class_mode\": \"categorical\",\n",
    "            \"color_mode\": \"rgb\",\n",
    "            \"shuffle\": False,\n",
    "            \"target_size\": [10, 10]\n",
    "          }\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "read_source_data_set = SourceReaders.read_disk_keras_single_input_iterator\n",
    "\n",
    "data_bunch_fit = tasks.read_train_valid_test_data_bunch(read_source_data_set,\n",
    "                                                        source_params[\"train\"],\n",
    "                                                        source_params[\"valid\"],\n",
    "                                                        source_params[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mercury_ml.common.data_bunch.DataBunch object at 0x0000023DF0C7BC88>\n"
     ]
    }
   ],
   "source": [
    "print(data_bunch_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Define model\n",
    "\n",
    "Here we define the model we will use (in this case, we use the small function in function \"define_conv_simple\", but any valid tensorflow.keras model would work here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ModelDefinitions.define_conv_simple(\n",
    "    input_size = [10, 10],\n",
    "    nb_classes=2,\n",
    "    final_activation=\"softmax\",\n",
    "    dropout_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "optimizer_params = {\n",
    "        \"optimizer_name\": \"Adam\",\n",
    "        \"optimizer_params\": {\n",
    "          \"lr\": 0.001\n",
    "        }\n",
    "      }\n",
    "optimizer = OptimizerFetchers.get_keras_optimizer(**optimizer_params)\n",
    "loss_function = LossFunctionFetchers.get_keras_loss(\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = ModelCompilers.compile_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 3, 3, 4)           304       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 1, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 320\n",
      "Trainable params: 320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Define the callsbacks for training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "callback_params_early_st = {\n",
    "          \"patience\": 2,\n",
    "          \"monitor\": \"val_loss\",\n",
    "          \"min_delta\": 0.001\n",
    "        }\n",
    "callback_params_early_model_ch = {\n",
    "    \"filepath\": \"./example_results/local/\"+session_id+\"/model_checkpoint/last_best_model.h5\",\n",
    "    \"save_best_only\": True\n",
    "}\n",
    "\n",
    "callbacks = [CallBacks.early_stopping(callback_params_early_st),\n",
    "             CallBacks.model_checkpoint(callback_params_early_model_ch)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 117ms/step - loss: 0.6909 - acc: 0.4286 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6827 - acc: 0.2143 - val_loss: 0.6911 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6734 - acc: 0.3571 - val_loss: 0.6679 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6737 - acc: 0.5000 - val_loss: 0.6702 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6824 - acc: 0.5000 - val_loss: 0.6882 - val_acc: 0.6667\n",
      "return_best_model set to False. Returning model from last epoch\n"
     ]
    }
   ],
   "source": [
    "model = ModelFitters.fit_generator(\n",
    "    model = model,\n",
    "    data_bunch = data_bunch_fit,\n",
    "    callbacks = callbacks,\n",
    "    epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we specifiy the model savers (i.e. in what format should be model be saved, and which paramters should be used for the storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_model_dict = {\n",
    "    \"save_hdf5\":ModelSavers.save_hdf5,\n",
    "    \"save_tensorflow_saved_model\":ModelSavers.save_tensorflow_saved_model\n",
    "}\n",
    "\n",
    "model_local_dir =\"./example_results/local/\"+session_id+\"/models\"\n",
    "model_remote_dir = \"./example_results/remote/\"+session_id+\"/models\"\n",
    "model_object_name= \"fit_example__\"+session_id\n",
    "save_model_params = {\n",
    "      \"save_hdf5\": {\n",
    "        \"local_dir\": model_local_dir,\n",
    "        \"remote_dir\": model_remote_dir,\n",
    "        \"filename\": model_object_name+\"__hdf5\",\n",
    "        \"extension\": \".h5\",\n",
    "        \"overwrite_remote\": True\n",
    "      },\n",
    "      \"save_tensorflow_saved_model\": {\n",
    "        \"local_dir\": model_local_dir,\n",
    "        \"remote_dir\": model_remote_dir,\n",
    "        \"filename\": model_object_name+\"__tf_serving_predict\",\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we use the \"tasks\" API to store the model in each of the provided formats, as well as copying the model to a \"remote\" location (in this example we simply copy to another local folder, but this would normally be used in combination with S3, GCS, HDFS etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2,
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for model_format, save_model in save_model_dict.items():\n",
    "    \n",
    "    tasks.store_model(save_model=save_model,\n",
    "                      model=model,\n",
    "                      copy_from_local_to_remote = ArtifactCopiers.copy_from_disk_to_disk,\n",
    "                      **save_model_params[model_format]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we use the built-in evaluate functions that are available in tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0508 15:49:27.535490 25028 encoders.py:368] json-tricks: numpy scalar serialization is experimental and may work differently in future versions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"loss\": 0.6924253106117249,\n",
      "  \"acc\": 0.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_bunch_fit.test.predictions = PredictionFunctions.predict_generator(model=model, data_set=data_bunch_fit.test)\n",
    "metrics =  ModelEvaluators.evaluate_generator(model, data_bunch_fit.test)\n",
    "print(json_tricks.dumps(metrics, indent=2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we use the mercury_ml.common.tasks API to produce cutom metric evaluations. For these, we will evaluate metrics based on Numpy calculations, and therefore need to first transform our data_bunch to Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_params = {\n",
    "        \"data_set_names\": [\"test\"],\n",
    "        \"params\": {\n",
    "          \"transform_to\": \"numpy\",\n",
    "          \"data_wrapper_params\": {\n",
    "            \"predictions\": {},\n",
    "            \"index\": {},\n",
    "            \"targets\": {}\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "data_bunch_metric = data_bunch_fit.transform(**transformation_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mercury_ml.common.data_bunch.DataBunch object at 0x0000023DF0C4AF60>\n"
     ]
    }
   ],
   "source": [
    "print(data_bunch_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_label_metrics_dict = {\n",
    "    \"evaluate_numpy_accuracy\":CustomLabelMetrics.evaluate_numpy_accuracy,\n",
    "    \"evaluate_numpy_auc\":CustomLabelMetrics.evaluate_numpy_auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Accuracy\": {\n",
      "    \"cat\": 0.5,\n",
      "    \"dog\": 0.5\n",
      "  },\n",
      "  \"AUC\": {\n",
      "    \"cat\": 0.5555555555555556,\n",
      "    \"dog\": 0.5555555555555556\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "custom_label_metrics = tasks.evaluate_label_metrics(data_bunch_metric.test, custom_label_metrics_dict)\n",
    "print(json_tricks.dumps(custom_label_metrics, indent=2))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
