{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# H2O workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.split(os.path.split(os.getcwd())[0])[0])\n",
    "config_filepath =\"./fit_config_h2o.json\"\n",
    "import uuid\n",
    "import json\n",
    "import datetime\n",
    "import getpass\n",
    "\n",
    "from mercury_ml.common import tasks\n",
    "from mercury_ml.common import utils\n",
    "from mercury_ml.common import containers as common_containers\n",
    "from mercury_ml.h2o import containers as h2o_containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For testing purposes only!\n",
    "\n",
    "if os.path.isdir(\"./example_results\"):\n",
    "    import shutil\n",
    "    shutil.rmtree(\"./example_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "These functions will help with the flow of this particular notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_bunch(data_bunch):\n",
    "\n",
    "    for data_set_name, data_set in data_bunch.__dict__.items():\n",
    "        print(\"{} <{}>\".format(data_set_name, type(data_set).__name__))\n",
    "        for data_wrapper_name, data_wrapper in data_set.__dict__.items():\n",
    "            print(\"  {} <{}>\".format(data_wrapper_name, type(data_wrapper).__name__))\n",
    "        print()\n",
    "        \n",
    "def maybe_transform(data_bunch, pre_execution_parameters):\n",
    "    if pre_execution_parameters:\n",
    "        return data_bunch.transform(**pre_execution_parameters)\n",
    "    else:\n",
    "        return data_bunch\n",
    "        \n",
    "def print_dict(d):\n",
    "    print(json.dumps(d, indent=2))\n",
    "\n",
    "def get_installed_packages():\n",
    "    import pip\n",
    "    try:\n",
    "        from pip._internal.operations import freeze\n",
    "    except ImportError:  # pip < 10.0\n",
    "        from pip.operations import freeze\n",
    "\n",
    "    packages = []\n",
    "    for p in freeze.freeze():\n",
    "        packages.append(p)\n",
    "\n",
    "    return packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_referenced_json_config(config_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = str(uuid.uuid4().hex) #unique. CAREFUL! This should be consciously run when you wish to create a new iteration of a model\n",
    "model_id = str(uuid.uuid4().hex)[:8] # this is *nearly* unique, but shorter (for illustration only!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update config\n",
    "\n",
    "The function `utils.recursively_update_config(config, string_formatting_dict)` allows us to use string formatting to replace placeholder strings with acctual values.\n",
    "\n",
    "for example: \n",
    "\n",
    "```python\n",
    ">>> config = {\"some_value\": \"some_string_{some_placeholder}\"}\n",
    ">>> string_formatting_dict = {\"some_placeholder\": \"ABC\"}\n",
    ">>> utils.recursively_update_config(config, string_formatting_dict)\n",
    ">>> print(config)\n",
    "{\"some_value\": \"some_string_ABC}\"}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First update `config[\"meta_info\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.recursively_update_config(config[\"meta_info\"], {\n",
    "    \"model_id\": model_id,\n",
    "    \"model_purpose\": config[\"meta_info\"][\"model_purpose\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use `config[\"meta_info\"]` to update the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.recursively_update_config(config, config[\"meta_info\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "\n",
    "Create a small dictionary with the session information. This will later be stored as a dictionary artifact with all the key run infomration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = {\n",
    "    \"time_stamp\": datetime.datetime.utcnow().isoformat()[:-3] + \"Z\",\n",
    "    \"run_by\": getpass.getuser(),\n",
    "    \"meta_info\": config[\"meta_info\"],\n",
    "    \"installed_packages\": get_installed_packages()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Session info\")\n",
    "print(json.dumps(session, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "These are the functions or classes we will be using in this workflow. We get / instatiate them all at the beginning using parameters under `config[\"initialization\"]`.\n",
    "\n",
    "Here we use mainly use `getattr` to fetch them via the `containers` module based on a string input in the config file. Providers could however also be fetched directly. The following three methods are all equivalent:\n",
    "\n",
    "```python\n",
    "# 1. (what we are using in this notebook)\n",
    "from ml_workflow.common import containers as common_containers\n",
    "source_reader=getattr(common_containers.SourceReaders, \"read_pandas_data_set\")\n",
    "\n",
    "# 2. \n",
    "from ml_workflow.common import containers as common_containers\n",
    "source_reader=common_containers.SourceReaders.read_pandas_data_set\n",
    "\n",
    "# 3.\n",
    "from ml_workflow.common.providers.source_reading import read_pandas_data_set\n",
    "source_reader=read_pandas_data_set\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "\n",
    "These helper functions will create instantiate class providers (`create_and_log`) or fetch function providers (`get_and_log`) based on the parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_log(container, class_name, params):\n",
    "    provider = getattr(container, class_name)(**params)\n",
    "    print(\"{}.{}\".format(container.__name__, class_name))\n",
    "    print(\"params: \", json.dumps(params, indent=2))\n",
    "    return provider\n",
    "\n",
    "def get_and_log(container, function_name):\n",
    "    provider = getattr(container, function_name)\n",
    "    print(\"{}.{}\".format(container.__name__, function_name))\n",
    "    return provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common\n",
    "\n",
    "These are providers that are universally relevant, regardless of which Machine Learning engine is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for storing dictionary artifacts to local disk\n",
    "store_artifact_locally = get_and_log(common_containers.LocalArtifactStorers,\n",
    "                                     config[\"init\"][\"store_artifact_locally\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for storing data-frame-like artifacts to local disk\n",
    "store_prediction_artifact_locally = get_and_log(common_containers.LocalArtifactStorers,\n",
    "                                                config[\"init\"][\"store_prediction_artifact_locally\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for copy artifacts from local disk to a remote store\n",
    "copy_from_local_to_remote = get_and_log(common_containers.ArtifactCopiers, config[\"init\"][\"copy_from_local_to_remote\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for reading source data. When called it will return an instance of type DataBunch \n",
    "read_source_data_set = get_and_log(common_containers.SourceReaders, config[\"init\"][\"read_source_data\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary of functions that calculate custom metrics\n",
    "custom_metrics_dict = {\n",
    "    custom_metric_name: get_and_log(common_containers.CustomMetrics, custom_metric_name) for custom_metric_name in config[\"init\"][\"custom_metrics\"][\"names\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary of functions that calculate custom label metrics\n",
    "custom_label_metrics_dict = {\n",
    "    custom_label_metric_name: get_and_log(common_containers.CustomLabelMetrics, custom_label_metric_name) for custom_label_metric_name in config[\"init\"][\"custom_label_metrics\"][\"names\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to initiate the h2o (or h2o sparkling) session\n",
    "initiate_session = get_and_log(h2o_containers.SessionInitiators, config[\"init\"][\"initiate_session\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch a built-in h2o model\n",
    "model = get_and_log(h2o_containers.ModelDefinitions, \n",
    "                    config[\"init\"][\"model_definition\"][\"name\"])(**config[\"init\"][\"model_definition\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that fits an h2o model\n",
    "fit = get_and_log(h2o_containers.ModelFitters, config[\"init\"][\"fit\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary of functions that save h2o models in various formats\n",
    "save_model_dict = {\n",
    "    save_model_function_name: get_and_log(h2o_containers.ModelSavers, save_model_function_name) for save_model_function_name in config[\"init\"][\"save_model\"][\"names\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that generates metrics from an h2o model\n",
    "evaluate = get_and_log(h2o_containers.ModelEvaluators, config[\"init\"][\"evaluate\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that generates metrics from an h2o model\n",
    "evaluate_threshold_metrics = get_and_log(h2o_containers.ModelEvaluators, config[\"init\"][\"evaluate_threshold_metrics\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that produces predictions using an h2o model\n",
    "predict = get_and_log(h2o_containers.PredictionFunctions, config[\"init\"][\"predict\"][\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "Here we use the providers defined above to execute various tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save (formatted) config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, config,\n",
    "                      **config[\"exec\"][\"save_formatted_config\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Config stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_formatted_config\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save session info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, session,\n",
    "                                 **config[\"exec\"][\"save_session\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Session dictionary stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_session\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save session artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in config[\"exec\"][\"save_session_artifacts\"][\"params\"][\"filenames\"]:\n",
    "    # save to local artifact store\n",
    "    common_containers.ArtifactCopiers.copy_from_disk_to_disk(source_dir=os.getcwd(),\n",
    "                                                   target_dir=config[\"exec\"][\"save_session_artifacts\"][\"params\"][\"local_dir\"],\n",
    "                                                   filename=filename,\n",
    "                                                   overwrite=False,\n",
    "                                                   delete_source=False)\n",
    "\n",
    "    # copy to remote artifact store\n",
    "    copy_from_local_to_remote(source_dir=config[\"exec\"][\"save_session_artifacts\"][\"params\"][\"local_dir\"],\n",
    "                              target_dir=config[\"exec\"][\"save_session_artifacts\"][\"params\"][\"remote_dir\"],\n",
    "                              filename=filename,\n",
    "                              overwrite=False,\n",
    "                              delete_source=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Session artifacts stored with following parameters\")\n",
    "print_dict(config[\"exec\"][\"save_session_artifacts\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initiate_session(**config[\"exec\"][\"initiate_session\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_source = tasks.read_train_valid_test_data_bunch(read_source_data_set,**config[\"exec\"][\"read_source_data\"][\"params\"] )\n",
    "print(\"Source data read using following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"read_source_data\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_fit = maybe_transform(data_bunch_source, config[\"exec\"][\"fit\"].get(\"pre_execution_transformation\"))\n",
    "\n",
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"fit\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit(model = model,\n",
    "            data_bunch = data_bunch_fit,\n",
    "            **config[\"exec\"][\"fit\"][\"params\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_format, save_model in save_model_dict.items():\n",
    "    \n",
    "    tasks.store_model(save_model=save_model,\n",
    "                      model=model,\n",
    "                      copy_from_local_to_remote = copy_from_local_to_remote,\n",
    "                      **config[\"exec\"][\"save_model\"][model_format]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model saved with following paramters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_metrics = maybe_transform(data_bunch_fit, config[\"exec\"][\"evaluate\"].get(\"pre_execution_transformation\"))\n",
    "\n",
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"evaluate\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_metrics, data_set_name)\n",
    "    metrics[data_set_name] = evaluate(model, data_set, data_set_name, **config[\"exec\"][\"evaluate\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resulting metrics: \\n\")\n",
    "print_dict(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_metrics, data_set_name)\n",
    "    threshold_metrics[data_set_name] = evaluate_threshold_metrics(model, data_set, data_set_name,\n",
    "                                                                  **config[\"exec\"][\"evaluate_threshold_metrics\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resulting metrics: \\n\")\n",
    "print_dict(threshold_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_threshold_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote, metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_predict = maybe_transform(data_bunch_metrics, config[\"exec\"][\"predict\"].get(\"pre_execution_transformation\"))\n",
    "    \n",
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"predict\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name in config[\"exec\"][\"predict\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_predict, data_set_name)\n",
    "    data_set.predictions = predict(model=model, data_set=data_set, **config[\"exec\"][\"predict\"][\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data predicted with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"predict\"].get(\"params\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_custom_metrics = maybe_transform(data_bunch_predict, \n",
    "                                            config[\"exec\"][\"evaluate_custom_metrics\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data transformed with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"evaluate_custom_metrics\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_custom_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate custom metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate_custom_metrics\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_custom_metrics, data_set_name)\n",
    "    custom_metrics[data_set_name]  = tasks.evaluate_metrics(data_set, custom_metrics_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resulting custom metrics: \\n\")\n",
    "print_dict(custom_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate custom label metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_label_metrics = {}\n",
    "for data_set_name in config[\"exec\"][\"evaluate_custom_label_metrics\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_custom_metrics, data_set_name)\n",
    "    custom_label_metrics[data_set_name] = tasks.evaluate_label_metrics(data_set, custom_label_metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resulting custom label metrics: \\n\")\n",
    "print_dict(custom_label_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_custom_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote,\n",
    "                          custom_metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Custom metrics saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_custom_metrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, params in config[\"exec\"][\"save_custom_label_metrics\"][\"data_sets\"].items():\n",
    "    tasks.store_artifacts(store_artifact_locally, copy_from_local_to_remote,\n",
    "                          custom_label_metrics[data_set_name], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Custom label metrics saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_custom_label_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare predictions for storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_prediction_preparation = maybe_transform(data_bunch_predict, \n",
    "                                                    config[\"exec\"][\"prepare_predictions_for_storage\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_prediction_preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare predictions and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name in config[\"exec\"][\"prepare_predictions_for_storage\"][\"data_set_names\"]:\n",
    "    data_set = getattr(data_bunch_prediction_preparation, data_set_name)\n",
    "    data_set.add_data_wrapper_via_concatenate(**config[\"exec\"][\"prepare_predictions_for_storage\"][\"params\"][\"predictions\"])\n",
    "    data_set.add_data_wrapper_via_concatenate(**config[\"exec\"][\"prepare_predictions_for_storage\"][\"params\"][\"targets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data_bunch(data_bunch_prediction_preparation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bunch_prediction_storage = maybe_transform(data_bunch_prediction_preparation, \n",
    "                                                config[\"exec\"][\"save_predictions\"].get(\"pre_execution_transformation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transformed data_bunch consists of: \\n\")\n",
    "print_data_bunch(data_bunch_prediction_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, data_set_params in config[\"exec\"][\"save_predictions\"][\"data_sets\"].items():\n",
    "    data_set = getattr(data_bunch_prediction_storage, data_set_name)\n",
    "    data_wrapper = getattr(data_set, data_set_params[\"data_wrapper_name\"])\n",
    "    \n",
    "    data_to_store = data_wrapper.underlying\n",
    "   \n",
    "    tasks.store_artifacts(store_prediction_artifact_locally, copy_from_local_to_remote,\n",
    "                          data_to_store, **data_set_params[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set_name, data_set_params in config[\"exec\"][\"save_targets\"][\"data_sets\"].items():\n",
    "    data_set = getattr(data_bunch_prediction_storage, data_set_name)\n",
    "    data_wrapper = getattr(data_set, data_set_params[\"data_wrapper_name\"])\n",
    "    \n",
    "    data_to_store = data_wrapper.underlying\n",
    "   \n",
    "    tasks.store_artifacts(store_prediction_artifact_locally, copy_from_local_to_remote,\n",
    "                          data_to_store, **data_set_params[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Targets saved with following parameters: \\n\")\n",
    "print_dict(config[\"exec\"][\"save_targets\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
